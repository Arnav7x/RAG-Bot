{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu sentence-transformers openai PyPDF2\n",
        "!pip install -q PyPDF2"
      ],
      "metadata": {
        "id": "A8_p9DA2N_gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBXF_sgJOBK8"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "print(\"FAISS working\")"
      ],
      "metadata": {
        "id": "uGRRjLN3OL1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter API key: \")\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "wPurwwMYOXOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "zVaCpK9qOrpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_pdf_text(file_name):\n",
        "    text = \"\"\n",
        "    with open(file_name, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Get uploaded filename\n",
        "pdf_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Extract\n",
        "pdf_text = extract_pdf_text(pdf_name)\n",
        "\n",
        "print(\"Preview:\\n\")\n",
        "print(pdf_text[:1000])\n"
      ],
      "metadata": {
        "id": "Zqny0TAxOvO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [pdf_text]"
      ],
      "metadata": {
        "id": "8SWgOPcKOaV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Simple chunking\n",
        "def chunk_text(text, chunk_size=200, overlap=40):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "\n",
        "    start = 0\n",
        "    while start < len(words):\n",
        "        end = start + chunk_size\n",
        "        chunk = words[start:end]\n",
        "        chunks.append(\" \".join(chunk))\n",
        "\n",
        "        start += chunk_size - overlap\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Apply to documents\n",
        "chunks = []\n",
        "for doc in documents:\n",
        "    chunks.extend(chunk_text(doc))\n",
        "\n",
        "print(\"Total chunks:\", len(chunks))\n",
        "\n",
        "\n",
        "# Embed\n",
        "embeddings = model.encode(chunks)\n",
        "embeddings = np.array(embeddings).astype(\"float32\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Sdu7AvgZOcaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(\"Indexed chunks:\", len(chunks))"
      ],
      "metadata": {
        "id": "Hgv2_kccOkeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, k=3):\n",
        "    q_emb = model.encode([query]).astype(\"float32\")\n",
        "    distances, indices = index.search(q_emb, k)\n",
        "\n",
        "    results = [chunks[i] for i in indices[0]]\n",
        "    return results"
      ],
      "metadata": {
        "id": "1eCQbOY_OvoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a QA assistant.\n",
        "Answer ONLY using the provided context.\n",
        "If the answer is not in the context, reply:\n",
        "\n",
        "\"I don't know based on the provided documents.\"\n",
        "\"\"\"\n",
        "\n",
        "def ask(query):\n",
        "    context = retrieve(query)\n",
        "    context_text = \"\\n\".join(context)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\"content\":SYSTEM_PROMPT},\n",
        "            {\"role\":\"user\",\"content\":\n",
        "             f\"Context:\\n{context_text}\\n\\nQuestion:{query}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "Wdp_iul-OxFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    q = input(\"You: \")\n",
        "    if q.lower() in [\"exit\",\"quit\"]:\n",
        "        break\n",
        "    print(\"Bot:\", ask(q))\n"
      ],
      "metadata": {
        "id": "AxMgxwnhPzoZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}